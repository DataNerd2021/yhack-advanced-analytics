{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.classify.util import accuracy\n",
    "\n",
    "df = pd.read_csv('Comments.csv')\n",
    "\n",
    "comments = df['Comment'].tolist()\n",
    "sentiments = df['Sentiment'].tolist()\n",
    "\n",
    "training = dict(zip(comments, sentiments))\n",
    "\n",
    "# Convert the dictionary to a list of tuples\n",
    "# Each tuple contains a comment and the corresponding sentiment label\n",
    "data_tuples = [(comment, sentiment) for comment, sentiment in training.items()]\n",
    "\n",
    "# Split into training and testing sets\n",
    "train_size = int(len(data_tuples) * 0.8)\n",
    "train_set, test_set = data_tuples[:train_size], data_tuples[train_size:]\n",
    "\n",
    "# Define a simple feature extractor\n",
    "def word_features(comment):\n",
    "    # Check if the comment is a string\n",
    "    if isinstance(comment, str):\n",
    "        return dict((word, True) for word in comment.split())\n",
    "    else:\n",
    "        # Handle non-string values (e.g., floats)\n",
    "        print(f\"Skipping non-string value: {comment}\")\n",
    "        return {}\n",
    "\n",
    "# Convert the data to the required format\n",
    "train_features = [(word_features(comment), sentiment) for (comment, sentiment) in train_set]\n",
    "test_features = [(word_features(comment), sentiment) for (comment, sentiment) in test_set]\n",
    "\n",
    "# Train the Naive Bayes classifier\n",
    "classifier = NaiveBayesClassifier.train(train_features)\n",
    "\n",
    "# Evaluate accuracy\n",
    "acc = accuracy(classifier, test_features)\n",
    "print(f'Accuracy: {acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import BernoulliNB\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X = []\n",
    "# y = []\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# bayes_classifier = BernoulliNB()\n",
    "\n",
    "# bayes_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Create a SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Example sentences\n",
    "sentences = [\n",
    "    \"I love NLTK! It's amazing.\",\n",
    "    \"This is a neutral statement.\",\n",
    "    \"I dislike negative reviews.\",\n",
    "]\n",
    "\n",
    "# Analyze sentiment for each sentence\n",
    "for sentence in sentences:\n",
    "    sentiment_score = sia.polarity_scores(sentence)\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Sentiment Score: {sentiment_score}\")\n",
    "    print(\"Sentiment:\", end=\" \")\n",
    "\n",
    "    # Determine sentiment based on compound score\n",
    "    if sentiment_score['compound'] >= 0.05:\n",
    "        print(\"Positive\")\n",
    "    elif sentiment_score['compound'] <= -0.05:\n",
    "        print(\"Negative\")\n",
    "    else:\n",
    "        print(\"Neutral\")\n",
    "\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
